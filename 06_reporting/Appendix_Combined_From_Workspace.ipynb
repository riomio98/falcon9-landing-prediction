{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a26e2d1f",
   "metadata": {},
   "source": [
    "# Appendix: Consolidated Workspace Assets\n",
    "This notebook scans all notebooks in the workspace and extracts key imports, helper functions, data loading, model code, and visualization snippets into a single reference artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406aeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook-Dateien Finden\n",
    "from pathlib import Path\n",
    "root = Path('..').resolve()\n",
    "notebooks = list(root.rglob('*.ipynb'))\n",
    "print('Such-Root:', root)\n",
    "print(f'Gefundene Notebooks: {len(notebooks)}')\n",
    "for p in notebooks[:10]:\n",
    "    print(' -', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook-JSON Laden\n",
    "import json\n",
    "loaded = []\n",
    "for p in notebooks:\n",
    "    try:\n",
    "        with open(p, 'r', encoding='utf-8') as f:\n",
    "            loaded.append((p, json.load(f)))\n",
    "    except json.JSONDecodeError:\n",
    "        print(f'Übersprungen (defekt): {p}')\n",
    "print(f'Geladene Notebooks: {len(loaded)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fa4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code- und Markdown-Zellen Extrahieren\n",
    "code_cells = []\n",
    "md_cells = []\n",
    "for path, nb in loaded:\n",
    "    for cell in nb.get('cells', []):\n",
    "        if cell.get('cell_type') == 'code':\n",
    "            code_cells.append(cell)\n",
    "        elif cell.get('cell_type') == 'markdown':\n",
    "            md_cells.append(cell)\n",
    "print(len(code_cells), 'Codezellen', '|', len(md_cells), 'Markdownzellen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe Vereinheitlichen\n",
    "import re\n",
    "import_lines = []\n",
    "for c in code_cells:\n",
    "    for line in c.get('source', []):\n",
    "        if re.match(r'^\\s*(import |from )', line):\n",
    "            import_lines.append(line.rstrip())\n",
    "unique_imports = sorted(dict.fromkeys(import_lines))\n",
    "merged_import_cell = {'cell_type': 'code', 'metadata': {}, 'source': [l + '\\n' for l in unique_imports]}\n",
    "print('Importe:', len(unique_imports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktionen Zusammenführen\n",
    "func_defs = []\n",
    "seen = set()\n",
    "for c in code_cells:\n",
    "    src = ''.join(c.get('source', []))\n",
    "    if src.strip().startswith('def '):\n",
    "        name = src.strip().split('def ')[1].split('(')[0]\n",
    "        if name not in seen:\n",
    "            seen.add(name)\n",
    "            func_defs.append(c)\n",
    "print('Funktionen:', len(func_defs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbf20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenlade- und Preprocessing-Schritte Sammeln\n",
    "load_cells = []\n",
    "keywords = ['read_csv', 'load', 'DataLoader', 'pd.read', 'np.load']\n",
    "for c in code_cells:\n",
    "    text = ''.join(c.get('source', []))\n",
    "    if any(k in text for k in keywords):\n",
    "        load_cells.append(c)\n",
    "print('Daten-/Preprocessing-Zellen:', len(load_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell-/Algorithmusdefinitionen Konsolidieren\n",
    "model_cells = []\n",
    "model_markers = ['class ', 'fit(', 'predict(', 'pipeline']\n",
    "for c in code_cells:\n",
    "    text = ''.join(c.get('source', []))\n",
    "    if any(m in text for m in model_markers):\n",
    "        model_cells.append(c)\n",
    "print('Modellzellen:', len(model_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierungen Zusammenstellen\n",
    "viz_cells = []\n",
    "viz_keys = ['plt.', 'seaborn', 'sns.', 'plot(', 'hist(', 'bar(', 'figure(']\n",
    "for c in code_cells:\n",
    "    txt = ''.join(c.get('source', []))\n",
    "    if any(v in txt for v in viz_keys):\n",
    "        viz_cells.append(c)\n",
    "print('Visualisierungen:', len(viz_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa47bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zellen Reihenfolge Heuristik Anwenden\n",
    "ordered_cells = []\n",
    "# Markdown Intro\n",
    "ordered_cells.append({'cell_type': 'markdown', 'metadata': {}, 'source': ['# Consolidated Workspace Notebook\\n']})\n",
    "# Imports\n",
    "ordered_cells.append(merged_import_cell)\n",
    "# Funktionen\n",
    "ordered_cells.extend(func_defs)\n",
    "# Daten Laden\n",
    "ordered_cells.extend(load_cells)\n",
    "# Modelle\n",
    "ordered_cells.extend(model_cells)\n",
    "# Visualisierung\n",
    "ordered_cells.extend(viz_cells)\n",
    "print('Reihenfolge erstellt:', len(ordered_cells), 'Zellen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b9fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kombiniertes Notebook Erzeugen\n",
    "combined = {\n",
    "    'cells': ordered_cells,\n",
    "    'metadata': {'language_info': {'name': 'python'}},\n",
    "    'nbformat': 4,\n",
    "    'nbformat_minor': 5\n",
    "}\n",
    "import json\n",
    "with open('combined_workspace.ipynb', 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined, f, ensure_ascii=False, indent=2)\n",
    "print('combined_workspace.ipynb geschrieben')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70baee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke-Tests Ausführen\n",
    "# Optional: einfache Auswertung ob kritische Symbole definiert sind\n",
    "expected_funcs = []\n",
    "try:\n",
    "    expected_funcs = [f.strip().split('def ')[1].split('(')[0] for f in [''.join(c['source']) for c in func_defs]]\n",
    "except Exception:\n",
    "    pass\n",
    "print('Erwartete Funktionen:', expected_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1902ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe Validieren und Speichern\n",
    "from pathlib import Path\n",
    "assert Path('combined_workspace.ipynb').exists(), 'Datei fehlt'\n",
    "print('Validierung OK')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
